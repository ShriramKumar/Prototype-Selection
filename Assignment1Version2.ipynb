{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gist\n",
    "Prototype selection is treated from a generative perspective here. A form for $p(X \\mid y,S)$ is assumed (S is the set of prototypes, X denotes the features and y the labels) where the probability of each point depends only on its nearest neighbor having the same label. Using this assumption, we maximize $f(S) = log\\lbrack p(S \\mid X,y) \\rbrack$  to find the set S of prototypes. Although this is a combinatorial optimization problem, we observe that f(S) is a submodular, monotone function. For this class of functions, approximate greedy inference has been both practically and theoretically shown to be useful. Here we use a greedy algorithm to maximize S.  \n",
    "\n",
    "# Description of cost function\n",
    "We take a more detailed look at the cost function in order to better understand the method. For some subset S of the input examples, let us consider the posterior probability of S.\n",
    "$$p(S | X,y) ∝ p(X | y,S)p(y | S)p(S)$$  \n",
    "$$\\implies \\log \\lbrack p(S | X, y) \\rbrack = \\log p(X | y, S)  + \\log p(y | S)  + \\log p(S)  + c$$  \n",
    "where c is a constant. We maximize this function assuming a specific form p(X | y,S) that satisfies two main conditions \n",
    "* It accurately captures the requirements for good classification of a nearest neighbour classifier\n",
    "* The resulting cost function is submodular\n",
    "\n",
    "To do this, we assume that the probability of a feature vector is related to the nearest neighbor which has the same label as that feature vector. Specifically, we assume\n",
    "$$p(X | y, S) =   maxr∈Syi eα||xi−r||2 (3) i$$\n",
    "where Syi represents the subset of S with label equal to yi.\n",
    "Substituting this in and making benign rearrangements, we get the cost function\n",
    "$$f(S) =   log p(xi | yi, S)  (4) i\n",
    "   ||xi −xk||2 log p(yi |S)  \n",
    "=⇒ f(S)=$$\n",
    "where $\\alpha$ and $\\beta$ are hyper-parameters and $p(yi \\mid S)$ is just the proportion of prototypes of label yi in set S. This function can be shown to be submodular. The proof could be done for example by showing that each p(xi | yi, S) is submodular and hence the sum is submodular.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "%matplotlib inline\n",
    "import cPickle, gzip, numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from itertools import chain\n",
    "import copy\n",
    "import random\n",
    "import sys\n",
    "import functools\n",
    "import scipy.spatial.distance as distance\n",
    "import math\n",
    "import cProfile\n",
    "import numpy as np\n",
    "import multiprocess\n",
    "from multiprocessing import Manager,Lock\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import hamming\n",
    "import heapq\n",
    "from collections import namedtuple\n",
    "import unittest\n",
    "import sklearn.metrics as metrics\n",
    "import os\n",
    "\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set = cPickle.load(f)\n",
    "f.close()\n",
    "\n",
    "train_x = 1*(train_set[0]>0.5)\n",
    "test_x = 1*(test_set[0]>0.5)\n",
    "valid_x = 1*(valid_set[0]>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0% done; Value of objective: 6\n",
      "1\n",
      "6\n",
      "50.0% done; Value of objective: 8\n",
      "2\n",
      "8\n",
      "75.0% done; Value of objective: 9\n",
      "3\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "def fprime_manual(f,x,s,args = ()):\n",
    "    \"\"\"\n",
    "    Manual calculation of marginal gain. If there is a optimal custom implementation\n",
    "    this should be overidden by supplying the fprime argument. Similar in spirit to \n",
    "    numerical gradient calculation.\n",
    "    \n",
    "    Parameters:\n",
    "    __________\n",
    "    f: callable f(x,s,*args); the objective function\n",
    "    x: element of input set to calculate marginal gain for\n",
    "    args: tuple (optinal); additional arguments to be supplied to f\n",
    "    \n",
    "    Returns:\n",
    "    _______\n",
    "    Marginal gain for element x, set s for function f\n",
    "    \"\"\"\n",
    "    if x in s:\n",
    "        return 0\n",
    "    else:\n",
    "        s_new = copy.deepcopy(s)\n",
    "        s_current = copy.deepcopy(s_new)\n",
    "        \n",
    "        s_new.append(x)\n",
    "        return f(s_new,*args) - f(s_current,*args)\n",
    "\n",
    "def fmax_submodular(f,s,fprime = None,sopt = None,k=float(\"Inf\"),verbose = False,args=()):\n",
    "    \n",
    "    \"\"\"\n",
    "    Maximize a submodular function using the greedy method.\n",
    "    \n",
    "    Parameters:\n",
    "    __________\n",
    "    s: set of elements, search is performed over the powerset P(s).\n",
    "    f: callable f(x,*args)\n",
    "    fprime: callable fprime(x,s);If not supplied, defaults to manual cauculation\n",
    "    args: tuple (optional) additional arguments to be passed to f\n",
    "    k: Cardinatlity constraint |S|<k is enforced\n",
    "\n",
    "    Returns:\n",
    "    _______\n",
    "    sopt: Optimal set for f\n",
    "    fopt: Value of the function at the optimal point\n",
    "    \"\"\"\n",
    "    \n",
    "    if fprime == None:\n",
    "        fprime = lambda x,s: fprime_manual(f,x,s,args)\n",
    "    \n",
    "    \"Checking if solution class has all required interfaces\"\n",
    "    if sopt == None:\n",
    "        sopt = []\n",
    "    elif hasattr(sopt,\"__len__\") & hasattr(sopt,\"append\") & hasattr(sopt,\"__contains__\"):\n",
    "        l = getattr(sopt,\"__len__\")\n",
    "        ap = getattr(sopt,\"append\")\n",
    "        in_func = getattr(sopt,\"__contains__\")\n",
    "        \n",
    "        if callable(l) & callable(ap) & callable(in_func):\n",
    "            pass\n",
    "        else:\n",
    "            raise TypeError(\"Solution class improperly defined\")\n",
    "    else:\n",
    "        raise TypeError(\"Solution class improperly defined\")\n",
    "        \n",
    "    fopt = 0\n",
    "\n",
    "    #Populate the heap\n",
    "    heap_fprimes = [(-fprime(x,sopt),x) for x in s]\n",
    "    heapq.heapify(heap_fprimes)\n",
    "    \n",
    "    #print heap_fprimes\n",
    "    \n",
    "    while len(sopt)<k:\n",
    "        x = heapq.heappop(heap_fprimes)\n",
    "        x = (-fprime(x[1],sopt),x[1])\n",
    "\n",
    "        while len(heap_fprimes)>0 and x[0]>heap_fprimes[0][0]:\n",
    "            heapq.heappush(heap_fprimes,x)\n",
    "            x = heapq.heappop(heap_fprimes)\n",
    "            x = (-fprime(x[1],sopt),x[1])\n",
    "\n",
    "        if x[0]>=0:\n",
    "            break\n",
    "        else:\n",
    "            sopt.append(x[1])\n",
    "            fopt += -x[0]\n",
    "        if verbose:\n",
    "            print str(100*float(len(sopt))/float(k)) + \"% done; Value of objective: \"+str(fopt)\n",
    "            print len(sopt)\n",
    "            print f(sopt)\n",
    "            \n",
    "    solution = namedtuple(\"solution\",[\"sopt\",\"fopt\"])\n",
    "    \n",
    "    return solution(sopt,fopt)\n",
    "\n",
    "def set_cover(s):\n",
    "\tif len(s)==0:\n",
    "\t\treturn 0\n",
    "\telse:\n",
    "\t\treturn len(reduce(lambda x,y:x|y,s))+1\n",
    "\n",
    "class testdf:\n",
    "    def __init__(self):\n",
    "        self.x =0\n",
    "\n",
    "soln = fmax_submodular(set_cover,[{1,2},{1,3,4},{1,2,4,5,6},{7,8}],k = 4,verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         100023 function calls in 281.882 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    2.681    2.681  281.882  281.882 <ipython-input-3-c5cd3c5b9fff>:3(__init__)\n",
      "        1    0.000    0.000  281.882  281.882 <string>:1(<module>)\n",
      "    50000    0.005    0.000    0.005    0.000 {len}\n",
      "    50000    0.004    0.000    0.004    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "       20  279.193   13.960  279.193   13.960 {numpy.core.multiarray.inner}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class solution:\n",
    "    \n",
    "    def __init__(self,x,y):\n",
    "        \n",
    "        self.train_data = x\n",
    "        self.train_labels = y\n",
    "        self.label_mapping = defaultdict(list)\n",
    "        self.distances = dict()\n",
    "        self.solution = []\n",
    "        self.data_currentdistances = [float(784)]*x.shape[0]\n",
    "        self.solution_sizes = defaultdict(int)\n",
    "        self.distance_matrices = dict()\n",
    "        self.index_map = dict()\n",
    "        \n",
    "        for index,label in enumerate(train_set[1]):\n",
    "            self.label_mapping[label].append(index)\n",
    "            self.index_map[index] = len(self.label_mapping[label])-1\n",
    "        \n",
    "        for label in self.label_mapping:\n",
    "            label_set = self.label_mapping[label]\n",
    "            self.distance_matrices[label] = np.inner(x[label_set,],1-x[label_set,]) + np.inner(1-x[label_set,],x[label_set,])\n",
    "            \n",
    "    def append(self,ind):\n",
    "        if ind in self.solution:\n",
    "            return False\n",
    "        else:\n",
    "            for matrix_index,point_index in enumerate(self.label_mapping[self.train_labels[ind]]):\n",
    "                new_dist = self.distance_matrices[self.train_labels[ind]][self.index_map[ind],matrix_index]\n",
    "                self.data_currentdistances[point_index] = min(self.data_currentdistances[point_index],new_dist)\n",
    "                \n",
    "            self.solution.append(ind)\n",
    "            self.solution_sizes[self.train_labels[ind]] += 1\n",
    "            return True\n",
    "    \n",
    "    def clear_solution(self):\n",
    "        self.solution = []\n",
    "        self.data_currentdistances = [float(784)]*self.train_data.shape[0]\n",
    "        self.solution_sizes = defaultdict(int)\n",
    "        return True\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.solution)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.solution)\n",
    "    \n",
    "    def __contains__(self,item):\n",
    "        return item in self.solution\n",
    "\n",
    "#Getting the solution construction profile    \n",
    "cProfile.run(\"s = solution(train_x,train_set[1])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient correctness using numerical calculation\n",
      "Error is: 2.33146835171e-15\n",
      "Error is: 7.77156117238e-16\n",
      "Error is: 5.27355936697e-15\n",
      "Error is: 1.12757025938e-14\n",
      "Error is: 3.77475828373e-15\n",
      "Error is: 1.19002030452e-14\n",
      "Error is: 8.32667268469e-16\n",
      "Error is: 7.91033905045e-15\n",
      "Error is: 7.29277749301e-15\n",
      "Error is: 3.44863027024e-15\n"
     ]
    }
   ],
   "source": [
    "def grad(ind,self,alpha = 0,beta = 0):\n",
    "        \n",
    "        delta = 0\n",
    "        if ind in self.solution:\n",
    "            return 0\n",
    "        else:\n",
    "                \n",
    "            for matrix_index,point_index in enumerate(self.label_mapping[self.train_labels[ind]]):\n",
    "                new_dist = self.distance_matrices[self.train_labels[ind]][self.index_map[ind],matrix_index]\n",
    "                if self.data_currentdistances[point_index] > new_dist:\n",
    "                    delta += self.data_currentdistances[point_index] - new_dist\n",
    "                if self.solution_sizes[self.train_labels[ind]] != 0:\n",
    "                    delta += alpha*math.log( (self.solution_sizes[self.train_labels[ind]]+1)/self.solution_sizes[self.train_labels[ind]] )\n",
    "\n",
    "            delta = delta/self.train_data.shape[0] - beta\n",
    "            \n",
    "            if len(self.solution)>0:\n",
    "                delta += alpha*math.log( float(len(self.solution))/(len(self.solution) + 1) )\n",
    "        \n",
    "            return delta\n",
    "\n",
    "def objective_function(s,alpha = 0,beta = 0):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    _________\n",
    "    s represents the dictionary containing the list of prototypes for each label\n",
    "    \"\"\"\n",
    "    cost = -sum(s.data_currentdistances)\n",
    "    \n",
    "    \n",
    "    for label in s.train_labels:\n",
    "        try:\n",
    "            cost += alpha*math.log(s.solution_sizes[label]/float(len(s.solution)))\n",
    "        except ValueError:\n",
    "            return float(\"-Inf\")\n",
    "            \n",
    "    cost = cost/float(s.train_data.shape[0]) - beta*len(s.solution)\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def predict(sol,test_data):\n",
    "    \n",
    "    s = np.array(sol.solution)\n",
    "    distances = np.dot(1-sol.train_data[s,:],np.transpose(test_data)) + np.dot(sol.train_data[s,:],1-np.transpose(test_data))\n",
    "    dist_indexes = np.zeros((test_data.shape[0],),dtype=int)\n",
    "    val = np.argmin(distances,axis=0,out =dist_indexes)\n",
    "    \n",
    "    return sol.train_labels[s[dist_indexes]]\n",
    "\n",
    "print \"Checking gradient correctness using numerical calculation\"\n",
    "\n",
    "count = 0\n",
    "while count<10:\n",
    "    s.clear_solution()\n",
    "    randomIndices = np.random.randint(0,len(train_set[1]),100)\n",
    "    map(s.append,randomIndices)\n",
    "\n",
    "    g = lambda x: fprime_manual(objective_function,x,s)\n",
    "    delta = np.random.randint(0,len(train_set[1]))\n",
    "    \n",
    "    count += 1\n",
    "    print \"Error is: \" + str(abs(grad(delta,s) - g(delta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         506860 function calls in 0.654 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      100    0.509    0.005    0.654    0.007 <ipython-input-3-c5cd3c5b9fff>:23(append)\n",
      "        1    0.000    0.000    0.654    0.654 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.654    0.654 {map}\n",
      "      100    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   506657    0.145    0.000    0.145    0.000 {min}\n",
      "\n",
      "\n",
      "         100005 function calls in 0.052 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.040    0.040    0.052    0.052 <ipython-input-4-dc6880ac9ab0>:22(objective_function)\n",
      "        1    0.000    0.000    0.052    0.052 <string>:1(<module>)\n",
      "    50001    0.003    0.000    0.003    0.000 {len}\n",
      "    50000    0.006    0.000    0.006    0.000 {math.log}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.003    0.003    0.003    0.003 {sum}\n",
      "\n",
      "\n",
      "-76.0063\n",
      "         4995 function calls in 0.009 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.008    0.008    0.009    0.009 <ipython-input-4-dc6880ac9ab0>:1(grad)\n",
      "        1    0.000    0.000    0.009    0.009 <string>:1(<module>)\n",
      "        3    0.000    0.000    0.000    0.000 {len}\n",
      "     4989    0.001    0.000    0.001    0.000 {math.log}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n",
      "0.08698\n"
     ]
    }
   ],
   "source": [
    "randomIndices = np.random.randint(0,len(train_set[1]),100)\n",
    "\n",
    "s.clear_solution()\n",
    "\n",
    "#Profiling the prototype add time\n",
    "cProfile.run(\"map(s.append,randomIndices)\")\n",
    "\n",
    "#Profiling the objective function evaluation time\n",
    "cProfile.run('o = objective_function(s)')\n",
    "print o\n",
    "\n",
    "#Gradient evaluation time\n",
    "cProfile.run(\"d = grad(110,s)\")\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model learning\n",
      "2.0% done; Value of objective: 83.84404\n",
      "1\n",
      "-inf\n",
      "4.0% done; Value of objective: 157.06422\n",
      "2\n",
      "-inf\n",
      "6.0% done; Value of objective: 227.24598\n",
      "3\n",
      "-inf\n",
      "8.0% done; Value of objective: 297.0655\n",
      "4\n",
      "-inf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c309b64e3328>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Starting model learning\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msol_optim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmax_submodular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfprime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msol_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mpred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-27d2026b9b30>\u001b[0m in \u001b[0;36mfmax_submodular\u001b[0;34m(f, s, fprime, sopt, k, verbose, args)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mheapq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheappush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheap_fprimes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheapq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheappop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheap_fprimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfprime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-dc6880ac9ab0>\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(ind, self, alpha, beta)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmatrix_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpoint_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mnew_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance_matrices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatrix_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_currentdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoint_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnew_dist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                     \u001b[0mdelta\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_currentdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoint_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnew_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolution_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "readings = []\n",
    "s.clear_solution()\n",
    "\n",
    "soln = namedtuple(\"soln\",[\"sopt\",\"fopt\"])\n",
    "sol_optim = soln(copy.deepcopy(s),0)\n",
    "\n",
    "for subset_size in [50,100,200,500,1000,5000,10000]:\n",
    "\n",
    "    print \"Starting model learning\"\n",
    "    sol_optim = fmax_submodular(objective_function,range(len(train_set[1])),fprime = grad,sopt = sol_optim.sopt,k=subset_size,verbose = True)\n",
    "    pred_test = predict(sol_optim.sopt,test_x)\n",
    "    \n",
    "    ac = metrics.accuracy_score(pred_test,test_set[1])\n",
    "    pr = metrics.precision_recall_fscore_support(pred_test,test_set[1],average=\"macro\")\n",
    "    vlist = list(pr)\n",
    "    vlist = [\"Optim\",ac,subset_size] + vlist[0:-1]\n",
    "    readings.append(vlist)\n",
    "    \n",
    "    print \"Done with model learning\"\n",
    "    \n",
    "    trials = 0\n",
    "    while trials<20:\n",
    "        randomIndices = np.random.randint(0,len(train_set[1]),subset_size)\n",
    "        s.clear_solution()\n",
    "        map(s.append,randomIndices)\n",
    "        pred_test = predict(s,test_x)\n",
    "\n",
    "        ac = metrics.accuracy_score(pred_test,test_set[1])\n",
    "        pr = metrics.precision_recall_fscore_support(pred_test,test_set[1],average=\"macro\")\n",
    "        vlist = list(pr)\n",
    "        vlist = [\"Random\",ac,subset_size] + vlist[0:-1]\n",
    "        readings.append(vlist)\n",
    "        trials += 1\n",
    "        \n",
    "    print \"Random model evaluation done\"\n",
    "    \n",
    "with open('Readings.dat','w') as f:\n",
    "    cPickle.dump(readings,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame(readings,columns=['Algorithm','Accuracy','SubsetSize','Precision','Recall','Fscore'])\n",
    "print data\n",
    "filtdat = data[data.Algorithm == 'Random']\n",
    "ax1 = filtdat.plot(x = 'SubsetSize', y = 'Accuracy', kind = 'box')\n",
    "\n",
    "#filtdat = data[data.Algorithm == 'Optim']\n",
    "#ax2 = filtdat.plot(x = 'SubsetSize', y = 'Accuracy', kind = 'line')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x^{2}/2$ is the value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
